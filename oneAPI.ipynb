{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mahesh-Alyana/oneAPI-Intel/blob/varun/oneAPI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MqMot_ZAmyMR",
        "outputId": "5a57b983-fbe7-4027-91d8-a5dcc386f7c2"
      },
      "id": "MqMot_ZAmyMR",
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import string\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv(\"/content/training_data_sentiment.csv\")\n",
        "\n",
        "# Remove unnecessary columns\n",
        "df = df.drop(['Source', 'PublishDate'], axis=1)\n",
        "\n",
        "# Remove missing values\n",
        "df = df.dropna()\n",
        "\n",
        "# Define stopwords and lemmatizer\n",
        "stop_words = set(stopwords.words('english'))\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "# Define function for text preprocessing\n",
        "def preprocess_text(text):\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "    \n",
        "    # Remove punctuation\n",
        "    text = text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
        "    \n",
        "    # Tokenize text\n",
        "    tokens = nltk.word_tokenize(text)\n",
        "    \n",
        "    # Remove stopwords\n",
        "    tokens = [token for token in tokens if token not in stop_words]\n",
        "    \n",
        "    # Lemmatize tokens\n",
        "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
        "    \n",
        "    # Join tokens to form text again\n",
        "    text = \" \".join(tokens)\n",
        "    \n",
        "    return text\n",
        "\n",
        "# Preprocess text in the dataset\n",
        "df['clean_title'] = df['Title'].apply(preprocess_text)\n"
      ],
      "metadata": {
        "id": "eUWkp5OJmd2L"
      },
      "id": "eUWkp5OJmd2L",
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['clean_headline'] = df['Headline'].apply(preprocess_text)"
      ],
      "metadata": {
        "id": "LTnRET8Cml6A"
      },
      "id": "LTnRET8Cml6A",
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim\n",
        "\n",
        "# Convert preprocessed text to gensim dictionary and corpus\n",
        "texts = [doc.split() for doc in df['clean_title']]\n",
        "dictionary = gensim.corpora.Dictionary(texts)\n",
        "corpus = [dictionary.doc2bow(text) for text in texts]\n",
        "\n",
        "# Define number of topics and run LDA model\n",
        "num_topics = 4\n",
        "lda_model = gensim.models.LdaModel(corpus, num_topics=num_topics, id2word=dictionary, passes=10)\n",
        "\n",
        "# Print top words in each topic\n",
        "for topic in lda_model.show_topics(num_topics=num_topics):\n",
        "    print(topic)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hy1tLJsamw2j",
        "outputId": "f1990b60-6384-497e-e82e-e766a50d03f8"
      },
      "id": "Hy1tLJsamw2j",
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(0, '0.098*\"microsoft\" + 0.016*\"window\" + 0.015*\"microsofts\" + 0.013*\"10\" + 0.011*\"surface\" + 0.010*\"new\" + 0.009*\"’\" + 0.007*\"one\" + 0.006*\"cloud\" + 0.006*\"lumia\"')\n",
            "(1, '0.107*\"economy\" + 0.018*\"china\" + 0.018*\"economic\" + 0.015*\"global\" + 0.014*\"u\" + 0.012*\"palestinian\" + 0.009*\"say\" + 0.008*\"market\" + 0.008*\"growth\" + 0.008*\"2016\"')\n",
            "(2, '0.130*\"obama\" + 0.029*\"obamas\" + 0.020*\"president\" + 0.013*\"trump\" + 0.008*\"say\" + 0.007*\"budget\" + 0.006*\"gun\" + 0.006*\"barack\" + 0.006*\"plan\" + 0.006*\"gop\"')\n",
            "(3, '0.055*\"economy\" + 0.028*\"palestine\" + 0.013*\"court\" + 0.012*\"state\" + 0.010*\"oil\" + 0.008*\"u\" + 0.008*\"supreme\" + 0.007*\"israel\" + 0.006*\"house\" + 0.006*\"white\"')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim\n",
        "\n",
        "# Convert preprocessed text to gensim dictionary and corpus\n",
        "texts = [doc.split() for doc in df['clean_headline']]\n",
        "dictionary = gensim.corpora.Dictionary(texts)\n",
        "corpus = [dictionary.doc2bow(text) for text in texts]\n",
        "\n",
        "# Define number of topics and run LDA model\n",
        "num_topics = 5\n",
        "lda_model = gensim.models.LdaModel(corpus, num_topics=num_topics, id2word=dictionary, passes=10)\n",
        "\n",
        "# Print top words in each topic\n",
        "for topic in lda_model.show_topics(num_topics=num_topics):\n",
        "    print(topic)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7KHgzObsnm92",
        "outputId": "841f7d97-11cd-4c92-f00d-8da7b3091902"
      },
      "id": "7KHgzObsnm92",
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(0, '0.058*\"economy\" + 0.018*\"economic\" + 0.014*\"year\" + 0.010*\"u\" + 0.009*\"growth\" + 0.009*\"global\" + 0.009*\"market\" + 0.008*\"china\" + 0.008*\"said\" + 0.007*\"percent\"')\n",
            "(1, '0.069*\"obama\" + 0.062*\"president\" + 0.035*\"barack\" + 0.013*\"u\" + 0.011*\"said\" + 0.011*\"obamas\" + 0.010*\"state\" + 0.009*\"republican\" + 0.009*\"house\" + 0.009*\"washington\"')\n",
            "(2, '0.055*\"microsoft\" + 0.015*\"new\" + 0.012*\"window\" + 0.010*\"company\" + 0.009*\"10\" + 0.008*\"microsofts\" + 0.007*\"surface\" + 0.006*\"one\" + 0.006*\"announced\" + 0.006*\"’\"')\n",
            "(3, '0.025*\"palestine\" + 0.020*\"palestinian\" + 0.008*\"israel\" + 0.007*\"israeli\" + 0.005*\"east\" + 0.005*\"2016\" + 0.005*\"west\" + 0.004*\"democratic\" + 0.004*\"vote\" + 0.004*\"middle\"')\n",
            "(4, '0.019*\"minister\" + 0.010*\"said\" + 0.008*\"prime\" + 0.007*\"chief\" + 0.006*\"new\" + 0.006*\"government\" + 0.006*\"economic\" + 0.006*\"proposal\" + 0.005*\"state\" + 0.005*\"meeting\"')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['clean_title'], df['SentimentTitle'], test_size=0.2, random_state=42)\n",
        "\n",
        "# Vectorize text using TF-IDF\n",
        "vectorizer = TfidfVectorizer()\n",
        "X_train_vec = vectorizer.fit_transform(X_train)\n",
        "X_test_vec = vectorizer.transform(X_test)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "6Xqpg1VKowL9"
      },
      "id": "6Xqpg1VKowL9",
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_train.value_counts())\n"
      ],
      "metadata": {
        "id": "Dw8g8xbmp_Xs",
        "outputId": "30550b37-0512-4826-b05c-eff2be35698f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "Dw8g8xbmp_Xs",
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 0.000000    6645\n",
            " 0.041667     409\n",
            " 0.044194     368\n",
            "-0.041667     299\n",
            " 0.039528     283\n",
            "             ... \n",
            "-0.036182       1\n",
            " 0.027862       1\n",
            "-0.091213       1\n",
            " 0.073546       1\n",
            "-0.173529       1\n",
            "Name: SentimentTitle, Length: 6601, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Convert continuous values to discrete labels\n",
        "y_train = pd.cut(y_train, bins=[-float(\"inf\"),0, float(\"inf\")], labels=[0, 1])\n",
        "y_test = pd.cut(y_test, bins=[-float(\"inf\"), 0, float(\"inf\")], labels=[0, 1])"
      ],
      "metadata": {
        "id": "JkYXVD8ArNDo"
      },
      "id": "JkYXVD8ArNDo",
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_train.value_counts())\n"
      ],
      "metadata": {
        "id": "kgbrUMgeqXbK",
        "outputId": "097cac5f-785e-43f6-e5ce-f72af776733c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "kgbrUMgeqXbK",
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0    19814\n",
            "1    12592\n",
            "Name: SentimentTitle, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train SVM classifier\n",
        "svm = LinearSVC()\n",
        "svm.fit(X_train_vec, y_train)\n",
        "\n",
        "# Predict on test data\n",
        "y_pred = svm.predict(X_test_vec)\n",
        "y_pred = pd.cut(y_pred, bins=[-float(\"inf\"), 0, float(\"inf\")], labels=[0, 1])\n",
        "\n",
        "# Print classification report\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "7v5RMIn1pMhv",
        "outputId": "5c40170e-96c5-4cef-b0d2-965d793585f9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "7v5RMIn1pMhv",
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.86      0.84      4921\n",
            "           1       0.76      0.71      0.73      3181\n",
            "\n",
            "    accuracy                           0.80      8102\n",
            "   macro avg       0.79      0.78      0.79      8102\n",
            "weighted avg       0.80      0.80      0.80      8102\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred.value_counts()"
      ],
      "metadata": {
        "id": "7fmQt7hvtDt_",
        "outputId": "37a12ff3-0819-4b0b-8dbe-600842bd8803",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "7fmQt7hvtDt_",
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    5166\n",
              "1    2936\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['clean_headline'], df['SentimentHeadline'], test_size=0.2, random_state=42)\n",
        "\n",
        "# Vectorize text using TF-IDF\n",
        "vectorizer = TfidfVectorizer()\n",
        "X_train_vec = vectorizer.fit_transform(X_train)\n",
        "X_test_vec = vectorizer.transform(X_test)"
      ],
      "metadata": {
        "id": "ivTeEco5qrDa"
      },
      "id": "ivTeEco5qrDa",
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Convert continuous values to discrete labels\n",
        "y_train = pd.cut(y_train, bins=[-float(\"inf\"),0, float(\"inf\")], labels=[0, 1])\n",
        "y_test = pd.cut(y_test, bins=[-float(\"inf\"), 0, float(\"inf\")], labels=[0, 1])"
      ],
      "metadata": {
        "id": "zPCuwenKrUdl"
      },
      "id": "zPCuwenKrUdl",
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train SVM classifier\n",
        "svm = LinearSVC()\n",
        "svm.fit(X_train_vec, y_train)\n",
        "\n",
        "# Predict on test data\n",
        "y_pred = svm.predict(X_test_vec)\n",
        "y_pred = pd.cut(y_pred, bins=[-float(\"inf\"), 0, float(\"inf\")], labels=[0, 1])\n",
        "\n",
        "# Print classification report\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "k4BQQM_zq-jV",
        "outputId": "6b9d67dd-cecc-45ef-8077-4acb88c871ce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "k4BQQM_zq-jV",
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.84      0.82      4853\n",
            "           1       0.74      0.68      0.71      3249\n",
            "\n",
            "    accuracy                           0.77      8102\n",
            "   macro avg       0.77      0.76      0.76      8102\n",
            "weighted avg       0.77      0.77      0.77      8102\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred.value_counts()"
      ],
      "metadata": {
        "id": "2NDhmELDrCCv",
        "outputId": "3787d657-f2f4-4649-9e2e-16a67fabe801",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "2NDhmELDrCCv",
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    5114\n",
              "1    2988\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CVzR_VGWtHeW"
      },
      "id": "CVzR_VGWtHeW",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (OpenVINO 2020.3.2 LTS)",
      "language": "python",
      "name": "c003-python_3_lts"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}